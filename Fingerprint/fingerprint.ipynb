{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ebec71",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Import XGBoost's sklearn API\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def extract_features_from_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV with columns: [Time (s), Frame Length, Direction, Interarrival]\n",
    "    Returns a dictionary of features.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.sort_values(by='Time (s)', inplace=True)\n",
    "\n",
    "    frame_vals = df['Frame Length'].values\n",
    "    direction_vals = df['Direction'].values\n",
    "    interarrival_vals = df['Interarrival'].values\n",
    "\n",
    "    mean_frame = np.mean(frame_vals)\n",
    "    std_frame = np.std(frame_vals)\n",
    "    max_frame = np.max(frame_vals)\n",
    "    min_frame = np.min(frame_vals)\n",
    "    peaks_frame, _ = find_peaks(frame_vals)\n",
    "    num_peaks_frame = len(peaks_frame)\n",
    "\n",
    "    avg_direction = np.mean(direction_vals)\n",
    "    proportion_uplink = (direction_vals > 0).mean()\n",
    "    proportion_downlink = (direction_vals < 0).mean()\n",
    "\n",
    "    mean_ia = np.mean(interarrival_vals)\n",
    "    std_ia = np.std(interarrival_vals)\n",
    "    max_ia = np.max(interarrival_vals)\n",
    "    min_ia = np.min(interarrival_vals)\n",
    "    peaks_ia, _ = find_peaks(interarrival_vals)\n",
    "    num_peaks_ia = len(peaks_ia)\n",
    "\n",
    "    #duration = df['Time (s)'].iloc[-1] - df['Time (s)'].iloc[0]\n",
    "\n",
    "    features = {\n",
    "        'mean_frame': mean_frame,\n",
    "        'std_frame': std_frame,\n",
    "        #'max_frame': max_frame,\n",
    "        #'min_frame': min_frame,\n",
    "        #'num_peaks_frame': num_peaks_frame,\n",
    "\n",
    "        'avg_direction': avg_direction,\n",
    "        'proportion_uplink': proportion_uplink,\n",
    "        'proportion_downlink': proportion_downlink,\n",
    "\n",
    "        'mean_ia': mean_ia,\n",
    "        'std_ia': std_ia,\n",
    "        'max_ia': max_ia,\n",
    "        'min_ia': min_ia\n",
    "        #'num_peaks_ia': num_peaks_ia\n",
    "\n",
    "        #'duration': duration\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Folders containing your Class A/B CSV files\n",
    "    #classA_dir = 'classA/csv_a'\n",
    "    #classB_dir = 'classB/csv_b'\n",
    "    classA_dir = \"tst/csv/a_o\" # CSV files for Class A\n",
    "    classB_dir = \"tst/csv/b_o\"  # CSV files for Class B\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Load Class A\n",
    "    for filename in os.listdir(classA_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = os.path.join(classA_dir, filename)\n",
    "            feat_dict = extract_features_from_csv(csv_path)\n",
    "            X.append(feat_dict)\n",
    "            y.append(0)  # label=0 for Class A\n",
    "\n",
    "    # Load Class B\n",
    "    for filename in os.listdir(classB_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = os.path.join(classB_dir, filename)\n",
    "            feat_dict = extract_features_from_csv(csv_path)\n",
    "            X.append(feat_dict)\n",
    "            y.append(1)  # label=1 for Class B\n",
    "\n",
    "    # Convert feature dicts to a DataFrame\n",
    "    df_features = pd.DataFrame(X)\n",
    "    df_features['label'] = y\n",
    "\n",
    "    # Separate features and labels\n",
    "    feature_cols = [c for c in df_features.columns if c != 'label']\n",
    "    X_data = df_features[feature_cols].values\n",
    "    y_data = df_features['label'].values\n",
    "\n",
    "    # Check if you have at least 2 samples per class\n",
    "    # If not, consider removing stratify or adjusting test_size\n",
    "    # For demonstration, we do a normal train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_data, y_data, test_size=0.3, random_state=42, stratify=y_data\n",
    "    )\n",
    "\n",
    "    # Create an XGBoost classifier\n",
    "    # You can tune hyperparameters like n_estimators, learning_rate, max_depth, etc.\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=30,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=3,\n",
    "        random_state=43,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'  # needed in newer XGBoost versions\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = xgb_clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy (XGBoost): {acc:.3f}\")\n",
    "\n",
    "    # Cross-validation for a more robust estimate\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scores = cross_val_score(xgb_clf, X_data, y_data, cv=5)\n",
    "    print(f\"5-Fold CV Accuracy: {scores.mean():.3f} Â± {scores.std():.3f}\")\n",
    "\n",
    "    # Save the trained XGBoost model + feature columns\n",
    "    joblib.dump((xgb_clf, feature_cols), 'xgb_model_no.pkl')\n",
    "    print(\"Trained XGBoost model saved as 'xgb_model_no.pkl'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63105564",
   "metadata": {},
   "source": [
    "### Test result of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69330dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def extract_features_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.sort_values(by='Time (s)', inplace=True)\n",
    "\n",
    "    frame_vals = df['Frame Length'].values\n",
    "    direction_vals = df['Direction'].values\n",
    "    interarrival_vals = df['Interarrival'].values\n",
    "\n",
    "    mean_frame = np.mean(frame_vals)\n",
    "    std_frame = np.std(frame_vals)\n",
    "    max_frame = np.max(frame_vals)\n",
    "    min_frame = np.min(frame_vals)\n",
    "    peaks_frame, _ = find_peaks(frame_vals)\n",
    "    num_peaks_frame = len(peaks_frame)\n",
    "\n",
    "    avg_direction = np.mean(direction_vals)\n",
    "    proportion_uplink = (direction_vals > 0).mean()\n",
    "    proportion_downlink = (direction_vals < 0).mean()\n",
    "\n",
    "    mean_ia = np.mean(interarrival_vals)\n",
    "    std_ia = np.std(interarrival_vals)\n",
    "    max_ia = np.max(interarrival_vals)\n",
    "    min_ia = np.min(interarrival_vals)\n",
    "    peaks_ia, _ = find_peaks(interarrival_vals)\n",
    "    num_peaks_ia = len(peaks_ia)\n",
    "\n",
    "    #duration = df['Time (s)'].iloc[-1] - df['Time (s)'].iloc[0]\n",
    "\n",
    "    features = {\n",
    "        'mean_frame': mean_frame,\n",
    "        'std_frame': std_frame,\n",
    "        #'max_frame': max_frame,\n",
    "        #'min_frame': min_frame,\n",
    "        #'num_peaks_frame': num_peaks_frame,\n",
    "\n",
    "        'avg_direction': avg_direction,\n",
    "        'proportion_uplink': proportion_uplink,\n",
    "        'proportion_downlink': proportion_downlink,\n",
    "\n",
    "        'mean_ia': mean_ia,\n",
    "        'std_ia': std_ia,\n",
    "        'max_ia': max_ia,\n",
    "        'min_ia': min_ia\n",
    "        #'num_peaks_ia': num_peaks_ia\n",
    "\n",
    "        #'duration': duration\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Instead of a single CSV file, we will process all CSVs in this folder:\n",
    "    #folder_name = \"classA/testA\"  # <-- Change to your folder path containing test CSVs\n",
    "    #folder_name = \"classB/testB\"\n",
    "    #folder_name = \"tst/csv\"\n",
    "    folder_name = \"Test/csv_all\"\n",
    "    # 1. Load the trained XGBoost model + feature columns\n",
    "    xgb_clf, feature_cols = joblib.load('xgb_model_no.pkl')\n",
    "\n",
    "    # Loop over all CSV files in the specified folder\n",
    "    for filename in os.listdir(folder_name):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_file = os.path.join(folder_name, filename)\n",
    "\n",
    "            # 2. Extract features from this CSV\n",
    "            feat_dict = extract_features_from_csv(csv_file)\n",
    "\n",
    "            # 3. Arrange features in the same order as training\n",
    "            feat_values = [feat_dict[col] for col in feature_cols]\n",
    "            X_new = np.array([feat_values])  # shape (1, num_features)\n",
    "\n",
    "            # 4. Predict\n",
    "            predicted_class = xgb_clf.predict(X_new)[0]\n",
    "\n",
    "            # Print the result\n",
    "            if predicted_class == 0:\n",
    "                print(f\"{filename} => Class A\")\n",
    "            else:\n",
    "                print(f\"{filename} => Class B\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8dcdeb",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f55e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "def extract_features_from_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV with columns: [Time (s), Frame Length, Direction, Interarrival]\n",
    "    Returns a dictionary of features.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Sort by time column (adjust if your CSV has a different time column name)\n",
    "    df.sort_values(by='Time (s)', inplace=True)\n",
    "\n",
    "    # Extract numeric arrays\n",
    "    frame_vals = df['Frame Length'].values\n",
    "    direction_vals = df['Direction'].values\n",
    "    interarrival_vals = df['Interarrival'].values\n",
    "\n",
    "    # Frame Length features\n",
    "    mean_frame = np.mean(frame_vals)\n",
    "    std_frame = np.std(frame_vals)\n",
    "    max_frame = np.max(frame_vals)\n",
    "    min_frame = np.min(frame_vals)\n",
    "    peaks_frame, _ = find_peaks(frame_vals)\n",
    "    num_peaks_frame = len(peaks_frame)\n",
    "\n",
    "    # Direction features\n",
    "    avg_direction = np.mean(direction_vals)\n",
    "    proportion_uplink = (direction_vals > 0).mean()\n",
    "    proportion_downlink = (direction_vals < 0).mean()\n",
    "\n",
    "    # Interarrival features\n",
    "    mean_ia = np.mean(interarrival_vals)\n",
    "    std_ia = np.std(interarrival_vals)\n",
    "    max_ia = np.max(interarrival_vals)\n",
    "    min_ia = np.min(interarrival_vals)\n",
    "    peaks_ia, _ = find_peaks(interarrival_vals)\n",
    "    num_peaks_ia = len(peaks_ia)\n",
    "\n",
    "    # Duration\n",
    "    #duration = df['Time (s)'].iloc[-1] - df['Time (s)'].iloc[0]\n",
    "\n",
    "    features = {\n",
    "        'mean_frame': mean_frame,\n",
    "        'std_frame': std_frame,\n",
    "        #'max_frame': max_frame,\n",
    "        #'min_frame': min_frame,\n",
    "        #'num_peaks_frame': num_peaks_frame,\n",
    "\n",
    "        'avg_direction': avg_direction,\n",
    "        'proportion_uplink': proportion_uplink,\n",
    "        'proportion_downlink': proportion_downlink,\n",
    "\n",
    "        'mean_ia': mean_ia,\n",
    "        'std_ia': std_ia,\n",
    "        'max_ia': max_ia,\n",
    "        'min_ia': min_ia,\n",
    "        #'num_peaks_ia': num_peaks_ia\n",
    "\n",
    "        #'duration': duration\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Paths to your training data\n",
    "    #classA_dir = 'classA/csv_a'  # Folder containing CSVs for Class A\n",
    "    #classB_dir = 'classB/csv_b'  # Folder containing CSVs for Class B\n",
    "    classA_dir = \"tst/csv/a_o\" # CSV files for Class A\n",
    "    classB_dir = \"tst/csv/b_o\"  # CSV files for Class B\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Load Class A\n",
    "    for filename in os.listdir(classA_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = os.path.join(classA_dir, filename)\n",
    "            feat_dict = extract_features_from_csv(csv_path)\n",
    "            X.append(feat_dict)\n",
    "            y.append(0)  # Label 0 for Class A\n",
    "\n",
    "    # Load Class B\n",
    "    for filename in os.listdir(classB_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = os.path.join(classB_dir, filename)\n",
    "            feat_dict = extract_features_from_csv(csv_path)\n",
    "            X.append(feat_dict)\n",
    "            y.append(1)  # Label 1 for Class B\n",
    "\n",
    "    # Convert list of feature dicts to a DataFrame\n",
    "    df_features = pd.DataFrame(X)\n",
    "    df_features['label'] = y\n",
    "\n",
    "    # Separate features and labels\n",
    "    feature_cols = [c for c in df_features.columns if c != 'label']\n",
    "    X_data = df_features[feature_cols].values\n",
    "    y_data = df_features['label'].values\n",
    "\n",
    "    # Train-test split (70% train, 30% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_data, y_data, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Create a Random Forest\n",
    "    clf = RandomForestClassifier(n_estimators=60, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy (Random Forest): {acc:.3f}\")\n",
    "\n",
    "    # Cross-validation for a more robust estimate\n",
    "    scores = cross_val_score(clf, X_data, y_data, cv=5) #5\n",
    "    print(f\"5-Fold CV Accuracy: {scores.mean():.3f} Â± {scores.std():.3f}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    joblib.dump((clf, feature_cols), 'rf_model_nos.pkl')\n",
    "    print(\"Trained Random Forest model saved as 'rf_model_no.pkl'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800be0d",
   "metadata": {},
   "source": [
    "### Test result of Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def extract_features_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.sort_values(by='Time (s)', inplace=True)\n",
    "\n",
    "    frame_vals = df['Frame Length'].values\n",
    "    direction_vals = df['Direction'].values\n",
    "    interarrival_vals = df['Interarrival'].values\n",
    "\n",
    "    mean_frame = np.mean(frame_vals)\n",
    "    std_frame = np.std(frame_vals)\n",
    "    max_frame = np.max(frame_vals)\n",
    "    min_frame = np.min(frame_vals)\n",
    "    peaks_frame, _ = find_peaks(frame_vals)\n",
    "    num_peaks_frame = len(peaks_frame)\n",
    "\n",
    "    avg_direction = np.mean(direction_vals)\n",
    "    proportion_uplink = (direction_vals > 0).mean()\n",
    "    proportion_downlink = (direction_vals < 0).mean()\n",
    "\n",
    "    mean_ia = np.mean(interarrival_vals)\n",
    "    std_ia = np.std(interarrival_vals)\n",
    "    max_ia = np.max(interarrival_vals)\n",
    "    min_ia = np.min(interarrival_vals)\n",
    "    peaks_ia, _ = find_peaks(interarrival_vals)\n",
    "    num_peaks_ia = len(peaks_ia)\n",
    "\n",
    "    #duration = df['Time (s)'].iloc[-1] - df['Time (s)'].iloc[0]\n",
    "\n",
    "    features = {\n",
    "        'mean_frame': mean_frame,\n",
    "        'std_frame': std_frame,\n",
    "        #'max_frame': max_frame,\n",
    "        #'min_frame': min_frame,\n",
    "        #'num_peaks_frame': num_peaks_frame,\n",
    "\n",
    "        'avg_direction': avg_direction,\n",
    "        'proportion_uplink': proportion_uplink,\n",
    "        'proportion_downlink': proportion_downlink,\n",
    "\n",
    "        'mean_ia': mean_ia,\n",
    "        'std_ia': std_ia,\n",
    "        'max_ia': max_ia,\n",
    "        'min_ia': min_ia\n",
    "        #'num_peaks_ia': num_peaks_ia\n",
    "\n",
    "       # 'duration': duration\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Instead of a single CSV, we'll process all CSVs in this folder:\n",
    "    #folder_name = \"classA/testA\"  # <-- Change this to your folder path\n",
    "    #folder_name = \"classB/testB\" \n",
    "    folder_name = \"Test/csv_all\"\n",
    "\n",
    "    # 1. Load the trained Random Forest model and feature columns\n",
    "    clf, feature_cols = joblib.load('rf_model_nos.pkl')\n",
    "\n",
    "    # Loop over all CSV files in the specified folder\n",
    "    for filename in os.listdir(folder_name):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_file = os.path.join(folder_name, filename)\n",
    "\n",
    "            # 2. Extract features from the CSV\n",
    "            feat_dict = extract_features_from_csv(csv_file)\n",
    "\n",
    "            # 3. Arrange feature values in the correct order\n",
    "            feat_values = [feat_dict[col] for col in feature_cols]\n",
    "            X_new = np.array([feat_values])  # shape (1, num_features)\n",
    "\n",
    "            # 4. Predict\n",
    "            predicted_class = clf.predict(X_new)[0]\n",
    "\n",
    "            # Print result\n",
    "            if predicted_class == 0:\n",
    "                print(f\"{filename} => Class A\")\n",
    "            else:\n",
    "                print(f\"{filename} => Class B\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5761a",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For saving the trained model\n",
    "import joblib\n",
    "\n",
    "def extract_features_from_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV with columns: [Time (s), Frame Length, Direction, Interarrival]\n",
    "    Returns a dictionary of features.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.sort_values(by='Time (s)', inplace=True)\n",
    "\n",
    "    frame_vals = df['Frame Length'].values\n",
    "    direction_vals = df['Direction'].values\n",
    "    interarrival_vals = df['Interarrival'].values\n",
    "\n",
    "    # Frame Length features\n",
    "    mean_frame = np.mean(frame_vals)\n",
    "    std_frame = np.std(frame_vals)\n",
    "    max_frame = np.max(frame_vals)\n",
    "    min_frame = np.min(frame_vals)\n",
    "    peaks_frame, _ = find_peaks(frame_vals)\n",
    "    num_peaks_frame = len(peaks_frame)\n",
    "\n",
    "    # Direction features\n",
    "    avg_direction = np.mean(direction_vals)\n",
    "    proportion_uplink = (direction_vals > 0).mean()\n",
    "    proportion_downlink = (direction_vals < 0).mean()\n",
    "\n",
    "    # Interarrival features\n",
    "    mean_ia = np.mean(interarrival_vals)\n",
    "    std_ia = np.std(interarrival_vals)\n",
    "    max_ia = np.max(interarrival_vals)\n",
    "    min_ia = np.min(interarrival_vals)\n",
    "    peaks_ia, _ = find_peaks(interarrival_vals)\n",
    "    num_peaks_ia = len(peaks_ia)\n",
    "\n",
    "    # Duration\n",
    "    #duration = df['Time (s)'].iloc[-1] - df['Time (s)'].iloc[0]\n",
    "\n",
    "    features = {\n",
    "        'mean_frame': mean_frame,\n",
    "        'std_frame': std_frame,\n",
    "        #'max_frame': max_frame,\n",
    "        #'min_frame': min_frame,\n",
    "        #'num_peaks_frame': num_peaks_frame,\n",
    "\n",
    "        'avg_direction': avg_direction,\n",
    "        'proportion_uplink': proportion_uplink,\n",
    "        'proportion_downlink': proportion_downlink,\n",
    "\n",
    "        'mean_ia': mean_ia,\n",
    "        'std_ia': std_ia,\n",
    "        'max_ia': max_ia,\n",
    "        'min_ia': min_ia\n",
    "        #'num_peaks_ia': num_peaks_ia\n",
    "\n",
    "        #'duration': duration\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Paths to your training data\n",
    "    #classA_dir = 'classA/csv_a'  # CSV files for Class A\n",
    "    #classB_dir = 'classB/csv_b'  # CSV files for Class B\n",
    "    classA_dir = \"tst/csv/a_o\" # CSV files for Class A\n",
    "    classB_dir = \"tst/csv/b_o\"  # CSV files for Class B\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Load Class A\n",
    "    for filename in os.listdir(classA_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = os.path.join(classA_dir, filename)\n",
    "            feat_dict = extract_features_from_csv(csv_path)\n",
    "            X.append(feat_dict)\n",
    "            y.append(0)  # label 0 for Class A\n",
    "\n",
    "    # Load Class B\n",
    "    for filename in os.listdir(classB_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = os.path.join(classB_dir, filename)\n",
    "            feat_dict = extract_features_from_csv(csv_path)\n",
    "            X.append(feat_dict)\n",
    "            y.append(1)  # label 1 for Class B\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_features = pd.DataFrame(X)\n",
    "    df_features['label'] = y\n",
    "\n",
    "    # Split into features & labels\n",
    "    feature_cols = [c for c in df_features.columns if c != 'label']\n",
    "    X_data = df_features[feature_cols].values\n",
    "    y_data = df_features['label'].values\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_data, y_data, test_size=0.3, random_state=42, stratify=y_data\n",
    "    )\n",
    "\n",
    "    # Create a pipeline: scaling + SVM\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel='rbf', random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {acc:.3f}\")\n",
    "\n",
    "    # Optional cross-validation\n",
    "    scores = cross_val_score(pipe, X_data, y_data, cv=5) #5\n",
    "    print(f\"5-Fold CV Accuracy: {scores.mean():.3f} Â± {scores.std():.3f}\")\n",
    "\n",
    "    # Save the trained pipeline to a file (model.pkl)\n",
    "    joblib.dump(pipe, 'model_svm_no.pkl')\n",
    "    print(\"Trained model saved as model_svm_no.pkl\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856334c",
   "metadata": {},
   "source": [
    "### Test result of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def extract_features_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.sort_values(by='Time (s)', inplace=True)\n",
    "\n",
    "    frame_vals = df['Frame Length'].values\n",
    "    direction_vals = df['Direction'].values\n",
    "    interarrival_vals = df['Interarrival'].values\n",
    "\n",
    "    mean_frame = np.mean(frame_vals)\n",
    "    std_frame = np.std(frame_vals)\n",
    "    max_frame = np.max(frame_vals)\n",
    "    min_frame = np.min(frame_vals)\n",
    "    peaks_frame, _ = find_peaks(frame_vals)\n",
    "    num_peaks_frame = len(peaks_frame)\n",
    "\n",
    "    avg_direction = np.mean(direction_vals)\n",
    "    proportion_uplink = (direction_vals > 0).mean()\n",
    "    proportion_downlink = (direction_vals < 0).mean()\n",
    "\n",
    "    mean_ia = np.mean(interarrival_vals)\n",
    "    std_ia = np.std(interarrival_vals)\n",
    "    max_ia = np.max(interarrival_vals)\n",
    "    min_ia = np.min(interarrival_vals)\n",
    "    peaks_ia, _ = find_peaks(interarrival_vals)\n",
    "    num_peaks_ia = len(peaks_ia)\n",
    "\n",
    "    #duration = df['Time (s)'].iloc[-1] - df['Time (s)'].iloc[0]\n",
    "\n",
    "    features = {\n",
    "        'mean_frame': mean_frame,\n",
    "        'std_frame': std_frame,\n",
    "        #'max_frame': max_frame,\n",
    "        #'min_frame': min_frame,\n",
    "        #'num_peaks_frame': num_peaks_frame,\n",
    "\n",
    "        'avg_direction': avg_direction,\n",
    "        'proportion_uplink': proportion_uplink,\n",
    "        'proportion_downlink': proportion_downlink,\n",
    "\n",
    "        'mean_ia': mean_ia,\n",
    "        'std_ia': std_ia,\n",
    "        'max_ia': max_ia,\n",
    "        'min_ia': min_ia\n",
    "        #'num_peaks_ia': num_peaks_ia,\n",
    "\n",
    "        #'duration': duration\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Folder containing new CSV files to predict\n",
    "    #folder_name = \"classA/testA\"  # <-- Replace with your actual folder name\n",
    "    #folder_name = \"classB/testB\" \n",
    "    #folder_name = \"tst/csv\" \n",
    "    #folder_name = \"tst/csv/t\"\n",
    "    folder_name = \"Test/csv_all\"\n",
    "\n",
    "    # 1. Load the saved model (pipeline)\n",
    "    model = joblib.load('model_svm_no.pkl')\n",
    "\n",
    "    # 2. Loop over all CSV files in that folder\n",
    "    for filename in os.listdir(folder_name):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            csv_path = os.path.join(folder_name, filename)\n",
    "\n",
    "            # Extract features\n",
    "            feat_dict = extract_features_from_csv(csv_path)\n",
    "\n",
    "            # Convert dict to the same order of columns used in training\n",
    "            feature_cols = [\n",
    "                'mean_frame', 'std_frame',\n",
    "                'avg_direction', 'proportion_uplink', 'proportion_downlink',\n",
    "                'mean_ia', 'std_ia', 'max_ia', 'min_ia'\n",
    "            ]\n",
    "            feat_values = [feat_dict[col] for col in feature_cols]\n",
    "            X_new = np.array([feat_values])  # shape (1, 14) if you have 14 features\n",
    "\n",
    "            # Predict\n",
    "            predicted_class = model.predict(X_new)[0]\n",
    "\n",
    "            # Print the result\n",
    "            if predicted_class == 0:\n",
    "                print(f\"{filename} => Class A\")\n",
    "            else:\n",
    "                print(f\"{filename} => Class B\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1ec9e",
   "metadata": {},
   "source": [
    "## Using the results make the accuracy calculation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
