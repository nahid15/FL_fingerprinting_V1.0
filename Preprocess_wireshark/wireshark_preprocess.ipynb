{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37673e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyshark\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6acea",
   "metadata": {},
   "source": [
    "## Preprocess train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c16f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pyshark\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing your pcapng files\n",
    "input_directory = \"data/Train/pcap\"  # Change this to your directory path\n",
    "\n",
    "# Define the output directory for the CSV files\n",
    "output_directory = \"data/Train/csv\"  # Change this as needed\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Get lists of both pcapng and pcap files\n",
    "pcapng_files = glob.glob(os.path.join(input_directory, \"*.pcapng\"))\n",
    "pcap_files = glob.glob(os.path.join(input_directory, \"*.pcap\"))\n",
    "all_files = pcapng_files + pcap_files\n",
    "\n",
    "# Process each file\n",
    "for pcap_file in all_files:\n",
    "    print(f\"Processing file: {pcap_file}\")\n",
    "    \n",
    "    # Open the file with PyShark (both pcap and pcapng are supported)\n",
    "    capture = pyshark.FileCapture(pcap_file, display_filter='ip')\n",
    "    \n",
    "    data = []\n",
    "    ref_time = None  # Will store the sniff_time of the first packet as our reference\n",
    "    \n",
    "    for packet in capture:\n",
    "        # Only process packets that have both frame and IP layers\n",
    "        if hasattr(packet, 'frame_info') and hasattr(packet, 'ip'):\n",
    "            # Set the reference time using the first packet encountered\n",
    "            if ref_time is None:\n",
    "                ref_time = packet.sniff_time\n",
    "\n",
    "            # Calculate elapsed time (in seconds) since the reference time\n",
    "            elapsed_time = (packet.sniff_time - ref_time).total_seconds()\n",
    "\n",
    "            # Get the frame length (convert to int)\n",
    "            frame_length = int(packet.frame_info.len)\n",
    "\n",
    "            # Get IP addresses from the IP layer (not used in final CSV but available for debugging)\n",
    "            source_ip = packet.ip.src\n",
    "            destination_ip = packet.ip.dst\n",
    "\n",
    "            # Initialize ports as None; try to extract from TCP or UDP if available\n",
    "            source_port = None\n",
    "            destination_port = None\n",
    "            if hasattr(packet, 'tcp'):\n",
    "                source_port = int(packet.tcp.srcport)\n",
    "                destination_port = int(packet.tcp.dstport)\n",
    "            elif hasattr(packet, 'udp'):\n",
    "                source_port = int(packet.udp.srcport)\n",
    "                destination_port = int(packet.udp.dstport)\n",
    "\n",
    "            # Determine the direction based on port-to-port logic:\n",
    "            #   - If source IP is 127.0.0.1 and source port is 5000, then it's Downlink (-1).\n",
    "            #   - If destination IP is 127.0.0.1 and destination port is 5000 and source port is not 5000, then it's Uplink (1).\n",
    "            #   - Otherwise, 0.\n",
    "            direction = 0\n",
    "            if source_ip == \"127.0.0.1\" and source_port == 5000:\n",
    "                direction = -1\n",
    "            elif destination_ip == \"127.0.0.1\" and destination_port == 5000 and (source_port != 5000 if source_port is not None else True):\n",
    "                direction = 1\n",
    "\n",
    "            # Append the extracted data as a dictionary\n",
    "            data.append({\n",
    "                \"Time (s)\": elapsed_time,\n",
    "                \"Frame Length\": frame_length,\n",
    "                \"Direction\": direction\n",
    "            })\n",
    "\n",
    "    # Close the capture when done processing the file\n",
    "    capture.close()\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Calculate interarrival time by taking the difference between consecutive \"Time (s)\" values\n",
    "    df['Interarrival'] = df['Time (s)'].diff().fillna(0)\n",
    "\n",
    "\n",
    "    # Build the output CSV file name based on the input file's base name\n",
    "    base_filename = os.path.basename(pcap_file)\n",
    "    csv_filename = os.path.splitext(base_filename)[0] + \".csv\"\n",
    "    csv_filepath = os.path.join(output_directory, csv_filename)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_filepath, index=False)\n",
    "    print(f\"CSV saved: {csv_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd2cfef",
   "metadata": {},
   "source": [
    "## prerpocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pyshark\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing your pcapng files\n",
    "input_directory = \"data/Test/pcap\"  # Change this to your directory path\n",
    "#input_directory = \"data/Train/pcap\"  # Change this to your directory path\n",
    "\n",
    "# Define the output directory for the CSV files\n",
    "output_directory = \"data/Test/csv\"  # Change this as needed\n",
    "#output_directory = \"data/Traincsv\"  # Change this as needed\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Get lists of both pcapng and pcap files\n",
    "pcapng_files = glob.glob(os.path.join(input_directory, \"*.pcapng\"))\n",
    "pcap_files = glob.glob(os.path.join(input_directory, \"*.pcap\"))\n",
    "all_files = pcapng_files + pcap_files\n",
    "\n",
    "# Process each file\n",
    "for pcap_file in all_files:\n",
    "    print(f\"Processing file: {pcap_file}\")\n",
    "    for packet in capture:\n",
    "        # Only process packets that have both frame and IP layers\n",
    "        if hasattr(packet, 'frame_info') and hasattr(packet, 'ip'):\n",
    "            # Set the reference time using the first packet encountered\n",
    "            if ref_time is None:\n",
    "                ref_time = packet.sniff_time\n",
    "\n",
    "            # Calculate elapsed time (in seconds) since the reference time\n",
    "            elapsed_time = (packet.sniff_time - ref_time).total_seconds()\n",
    "\n",
    "            # Get the frame length (convert to int)\n",
    "            frame_length = int(packet.frame_info.len)\n",
    "\n",
    "            # Get IP addresses from the IP layer (not used in final CSV but available for debugging)\n",
    "            source_ip = packet.ip.src\n",
    "            destination_ip = packet.ip.dst\n",
    "\n",
    "            # Initialize ports as None; try to extract from TCP or directorory need to change between train and test to select the pcap fileUDP if available\n",
    "            source_port = None\n",
    "            destination_port = None\n",
    "            if hasattr(packet, 'tcp'):\n",
    "                source_port = int(packet.tcp.srcport)\n",
    "                destination_port = int(packet.tcp.dstport)\n",
    "            elif hasattr(packet, 'udp'):\n",
    "                source_port = int(packet.udp.srcport)\n",
    "                destination_port = int(packet.udp.dstport)\n",
    "\n",
    "            # Determine the direction based on port-to-port logic:\n",
    "            #   - If source IP is 127.0.0.1 and source port is 5000, then it's Downlink (-1).\n",
    "            #   - If destination IP is 127.0.0.1 and destination port is 5000 and source port is not 5000, then it's Uplink (1).\n",
    "            #   - Otherwise, 0.\n",
    "            direction = 0\n",
    "            if source_ip == \"127.0.0.1\" and source_port == 5000:\n",
    "                direction = -1\n",
    "            elif destination_ip == \"127.0.0.1\" and destination_port == 5000 and (source_port != 5000 if source_port is not None else True):\n",
    "                direction = 1\n",
    "\n",
    "            # Append the extracted data as a dictionary\n",
    "            data.append({\n",
    "                \"Time (s)\": elapsed_time,\n",
    "                \"Frame Length\": frame_length,\n",
    "                \"Direction\": direction\n",
    "            })\n",
    "\n",
    "    # Close the capture when done processing the file\n",
    "    capture.close()\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Calculate interarrival time by taking the difference between consecutive \"Time (s)\" values\n",
    "    df['Interarrival'] = df['Time (s)'].diff().fillna(0)\n",
    "\n",
    "\n",
    "    # Build the output CSV file name based on the input file's base name\n",
    "    base_filename = os.path.basename(pcap_file)\n",
    "    csv_filename = os.path.splitext(base_filename)[0] + \".csv\"\n",
    "    csv_filepath = os.path.join(output_directory, csv_filename)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_filepath, index=False)\n",
    "    print(f\"CSV saved: {csv_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
